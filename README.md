# Speech-Emotion-Recognition
Speech Emotion Recognition (SER) identifies human emotions from spoken language by analyzing speech patterns. It supports applications like customer service, mental health care, and affective computing, using signal processing, machine learning and Deep Learning techniques,  improve humanâ€“computer interaction.
Datasets

The model is trained and evaluated using several benchmark SER datasets:

    1.CREMA-D ( Crowd-Sourced Emotional Multi modal actors dataset)

    2.RAVDESS  (Ryerson Audio-Visual Database of Emotional Speech and Song)

    3.TESS (Toronto Emotional Speech Set)

    4.Surrey Audio-Visual Expressed Emotion Dataset

The combined dataset contains labeled audio samples across emotions such as angry, happy, fear, disgust, sad, neutral, calm, and surprise, with thousands of samples per class for robust training

# METHODOLOGY 
<img width="453" height="460" alt="image" src="https://github.com/user-attachments/assets/5476b05e-c4a4-44ae-a356-44c8ddb4995c" />


